{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Router Query Engine\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Lets start with the simplest form of agentic RAG, a router. \n",
    " \n",
    " Given a query, the router will pick one of several query engines to execute a query. \n",
    " \n",
    " We will build a simple router over a single document that can handle both question answering as well as summarization. Let's dive in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: llama-index 0.10.33\n",
      "Uninstalling llama-index-0.10.33:\n",
      "  Would remove:\n",
      "    /Users/wenda/anaconda3/bin/llamaindex-cli\n",
      "    /Users/wenda/anaconda3/lib/python3.11/site-packages/llama_index-0.10.33.dist-info/*\n",
      "    /Users/wenda/anaconda3/lib/python3.11/site-packages/llama_index/_bundle/*\n",
      "Proceed (Y/n)? ^C\n",
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
      "\u001b[0mCollecting llama-index\n",
      "  Obtaining dependency information for llama-index from https://files.pythonhosted.org/packages/5c/e4/bd320411b7fbc09b6f6efcbaa785ce8ad5d645ae234c612fb1c9ec4bec6f/llama_index-0.10.43-py3-none-any.whl.metadata\n",
      "  Downloading llama_index-0.10.43-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting llama-index-agent-openai<0.3.0,>=0.1.4 (from llama-index)\n",
      "  Obtaining dependency information for llama-index-agent-openai<0.3.0,>=0.1.4 from https://files.pythonhosted.org/packages/98/74/489ef00d285843bb1bddfd9c628997c68ab27ed04a4be1124a517260576c/llama_index_agent_openai-0.2.7-py3-none-any.whl.metadata\n",
      "  Downloading llama_index_agent_openai-0.2.7-py3-none-any.whl.metadata (678 bytes)\n",
      "Collecting llama-index-cli<0.2.0,>=0.1.2 (from llama-index)\n",
      "  Obtaining dependency information for llama-index-cli<0.2.0,>=0.1.2 from https://files.pythonhosted.org/packages/8c/1b/554b8da1c7b62a7660a3ab0adfdc13a6046cad45a2490c3640728164f058/llama_index_cli-0.1.12-py3-none-any.whl.metadata\n",
      "  Downloading llama_index_cli-0.1.12-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting llama-index-core==0.10.43 (from llama-index)\n",
      "  Obtaining dependency information for llama-index-core==0.10.43 from https://files.pythonhosted.org/packages/de/42/15762e2e6d493fe6da3304040de047b99b6918626bc9120f67af6922677c/llama_index_core-0.10.43-py3-none-any.whl.metadata\n",
      "  Downloading llama_index_core-0.10.43-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting llama-index-embeddings-openai<0.2.0,>=0.1.5 (from llama-index)\n",
      "  Obtaining dependency information for llama-index-embeddings-openai<0.2.0,>=0.1.5 from https://files.pythonhosted.org/packages/f2/9b/e551e94edf3bdae8ca3a456ee9f1a87ae5e903535ddfb87b28eda4c27456/llama_index_embeddings_openai-0.1.10-py3-none-any.whl.metadata\n",
      "  Downloading llama_index_embeddings_openai-0.1.10-py3-none-any.whl.metadata (604 bytes)\n",
      "Collecting llama-index-indices-managed-llama-cloud<0.2.0,>=0.1.2 (from llama-index)\n",
      "  Obtaining dependency information for llama-index-indices-managed-llama-cloud<0.2.0,>=0.1.2 from https://files.pythonhosted.org/packages/ef/7a/07f3be0a5a535382ca528b9f6b62316b43680396156ae3f799aec3577ebb/llama_index_indices_managed_llama_cloud-0.1.6-py3-none-any.whl.metadata\n",
      "  Downloading llama_index_indices_managed_llama_cloud-0.1.6-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting llama-index-legacy<0.10.0,>=0.9.48 (from llama-index)\n",
      "  Obtaining dependency information for llama-index-legacy<0.10.0,>=0.9.48 from https://files.pythonhosted.org/packages/02/0a/0da9d27b0c3b074c1be1151ff4a4558f077c93df463310adfb47d193dde2/llama_index_legacy-0.9.48-py3-none-any.whl.metadata\n",
      "  Downloading llama_index_legacy-0.9.48-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting llama-index-llms-openai<0.2.0,>=0.1.13 (from llama-index)\n",
      "  Obtaining dependency information for llama-index-llms-openai<0.2.0,>=0.1.13 from https://files.pythonhosted.org/packages/e9/c1/bf810861227f7f467d0559fda13a397f07b9b540d1399b390021bb9ee48b/llama_index_llms_openai-0.1.22-py3-none-any.whl.metadata\n",
      "  Downloading llama_index_llms_openai-0.1.22-py3-none-any.whl.metadata (559 bytes)\n",
      "Collecting llama-index-multi-modal-llms-openai<0.2.0,>=0.1.3 (from llama-index)\n",
      "  Obtaining dependency information for llama-index-multi-modal-llms-openai<0.2.0,>=0.1.3 from https://files.pythonhosted.org/packages/2e/cb/d69c14583adb42b72d472af8ffa13fe10b1e550c1f202cb39429e6b88d47/llama_index_multi_modal_llms_openai-0.1.6-py3-none-any.whl.metadata\n",
      "  Downloading llama_index_multi_modal_llms_openai-0.1.6-py3-none-any.whl.metadata (677 bytes)\n",
      "Collecting llama-index-program-openai<0.2.0,>=0.1.3 (from llama-index)\n",
      "  Obtaining dependency information for llama-index-program-openai<0.2.0,>=0.1.3 from https://files.pythonhosted.org/packages/69/12/d47f38e2f2c18398650db776ab7bec1a7e0ba83664ef04843f664da94126/llama_index_program_openai-0.1.6-py3-none-any.whl.metadata\n",
      "  Downloading llama_index_program_openai-0.1.6-py3-none-any.whl.metadata (715 bytes)\n",
      "Collecting llama-index-question-gen-openai<0.2.0,>=0.1.2 (from llama-index)\n",
      "  Obtaining dependency information for llama-index-question-gen-openai<0.2.0,>=0.1.2 from https://files.pythonhosted.org/packages/2d/22/39f3ac5702b0e8ffd4d5a383c7cb2da0eb60f63b95f739345e79b66bf977/llama_index_question_gen_openai-0.1.3-py3-none-any.whl.metadata\n",
      "  Downloading llama_index_question_gen_openai-0.1.3-py3-none-any.whl.metadata (785 bytes)\n",
      "Collecting llama-index-readers-file<0.2.0,>=0.1.4 (from llama-index)\n",
      "  Obtaining dependency information for llama-index-readers-file<0.2.0,>=0.1.4 from https://files.pythonhosted.org/packages/ff/e1/37bc2e995ca2c416f74a82b7fe9df5b8682af7c94e8792a4eb7ddf5d1ae8/llama_index_readers_file-0.1.23-py3-none-any.whl.metadata\n",
      "  Downloading llama_index_readers_file-0.1.23-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting llama-index-readers-llama-parse<0.2.0,>=0.1.2 (from llama-index)\n",
      "  Obtaining dependency information for llama-index-readers-llama-parse<0.2.0,>=0.1.2 from https://files.pythonhosted.org/packages/79/af/e9aaf5e8869dd8a759b83ab8847cfb84642f3f583332a1786b49c691bbc6/llama_index_readers_llama_parse-0.1.4-py3-none-any.whl.metadata\n",
      "  Downloading llama_index_readers_llama_parse-0.1.4-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting PyYAML>=6.0.1 (from llama-index-core==0.10.43->llama-index)\n",
      "  Obtaining dependency information for PyYAML>=6.0.1 from https://files.pythonhosted.org/packages/28/09/55f715ddbf95a054b764b547f617e22f1d5e45d83905660e9a088078fe67/PyYAML-6.0.1-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading PyYAML-6.0.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (2.1 kB)\n",
      "Collecting SQLAlchemy[asyncio]>=1.4.49 (from llama-index-core==0.10.43->llama-index)\n",
      "  Obtaining dependency information for SQLAlchemy[asyncio]>=1.4.49 from https://files.pythonhosted.org/packages/29/51/3baab95d7eea9816c59c8e093201288ce27651704927e03ccfe156b30792/SQLAlchemy-2.0.30-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading SQLAlchemy-2.0.30-cp311-cp311-macosx_11_0_arm64.whl.metadata (9.6 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.6 (from llama-index-core==0.10.43->llama-index)\n",
      "  Obtaining dependency information for aiohttp<4.0.0,>=3.8.6 from https://files.pythonhosted.org/packages/4e/78/266be6e31daad1a2dc99c777dfb12b62044691ec573b6e48409a0d804fc7/aiohttp-3.9.5-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading aiohttp-3.9.5-cp311-cp311-macosx_11_0_arm64.whl.metadata (7.5 kB)\n",
      "Collecting dataclasses-json (from llama-index-core==0.10.43->llama-index)\n",
      "  Obtaining dependency information for dataclasses-json from https://files.pythonhosted.org/packages/92/70/382283d80cb998ebc0089428b109bbe606ec9dce891a3cb1468c03ed0ad6/dataclasses_json-0.6.6-py3-none-any.whl.metadata\n",
      "  Downloading dataclasses_json-0.6.6-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting deprecated>=1.2.9.3 (from llama-index-core==0.10.43->llama-index)\n",
      "  Obtaining dependency information for deprecated>=1.2.9.3 from https://files.pythonhosted.org/packages/20/8d/778b7d51b981a96554f29136cd59ca7880bf58094338085bcf2a979a0e6a/Deprecated-1.2.14-py2.py3-none-any.whl.metadata\n",
      "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting dirtyjson<2.0.0,>=1.0.8 (from llama-index-core==0.10.43->llama-index)\n",
      "  Obtaining dependency information for dirtyjson<2.0.0,>=1.0.8 from https://files.pythonhosted.org/packages/68/69/1bcf70f81de1b4a9f21b3a62ec0c83bdff991c88d6cc2267d02408457e88/dirtyjson-1.0.8-py3-none-any.whl.metadata\n",
      "  Downloading dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting fsspec>=2023.5.0 (from llama-index-core==0.10.43->llama-index)\n",
      "  Obtaining dependency information for fsspec>=2023.5.0 from https://files.pythonhosted.org/packages/8f/df/de2c06b316142063b6ccccc97cdc54185e3af771aa4f056d56f0db0e3466/fsspec-2024.6.0-py3-none-any.whl.metadata\n",
      "  Downloading fsspec-2024.6.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting httpx (from llama-index-core==0.10.43->llama-index)\n",
      "  Obtaining dependency information for httpx from https://files.pythonhosted.org/packages/41/7b/ddacf6dcebb42466abd03f368782142baa82e08fc0c1f8eaa05b4bae87d5/httpx-0.27.0-py3-none-any.whl.metadata\n",
      "  Downloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting llamaindex-py-client<0.2.0,>=0.1.18 (from llama-index-core==0.10.43->llama-index)\n",
      "  Obtaining dependency information for llamaindex-py-client<0.2.0,>=0.1.18 from https://files.pythonhosted.org/packages/5e/9c/a1a3086f023a8957ebd527c98d9356b6dd9409edef827ffdeee484f47abf/llamaindex_py_client-0.1.19-py3-none-any.whl.metadata\n",
      "  Downloading llamaindex_py_client-0.1.19-py3-none-any.whl.metadata (760 bytes)\n",
      "Collecting nest-asyncio<2.0.0,>=1.5.8 (from llama-index-core==0.10.43->llama-index)\n",
      "  Obtaining dependency information for nest-asyncio<2.0.0,>=1.5.8 from https://files.pythonhosted.org/packages/a0/c4/c2971a3ba4c6103a3d10c4b0f24f461ddc027f0f09763220cf35ca1401b3/nest_asyncio-1.6.0-py3-none-any.whl.metadata\n",
      "  Downloading nest_asyncio-1.6.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting networkx>=3.0 (from llama-index-core==0.10.43->llama-index)\n",
      "  Obtaining dependency information for networkx>=3.0 from https://files.pythonhosted.org/packages/38/e9/5f72929373e1a0e8d142a130f3f97e6ff920070f87f91c4e13e40e0fba5a/networkx-3.3-py3-none-any.whl.metadata\n",
      "  Downloading networkx-3.3-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting nltk<4.0.0,>=3.8.1 (from llama-index-core==0.10.43->llama-index)\n",
      "  Obtaining dependency information for nltk<4.0.0,>=3.8.1 from https://files.pythonhosted.org/packages/a6/0a/0d20d2c0f16be91b9fa32a77b76c60f9baf6eba419e5ef5deca17af9c582/nltk-3.8.1-py3-none-any.whl.metadata\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting numpy (from llama-index-core==0.10.43->llama-index)\n",
      "  Obtaining dependency information for numpy from https://files.pythonhosted.org/packages/1a/2e/151484f49fd03944c4a3ad9c418ed193cfd02724e138ac8a9505d056c582/numpy-1.26.4-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading numpy-1.26.4-cp311-cp311-macosx_11_0_arm64.whl.metadata (114 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.8/114.8 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting openai>=1.1.0 (from llama-index-core==0.10.43->llama-index)\n",
      "  Obtaining dependency information for openai>=1.1.0 from https://files.pythonhosted.org/packages/11/e0/4ddc922d454cc96dcdbc1c0b64fb886b8633fbe470b6e4c749dce06ab6fa/openai-1.32.0-py3-none-any.whl.metadata\n",
      "  Downloading openai-1.32.0-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting pandas (from llama-index-core==0.10.43->llama-index)\n",
      "  Obtaining dependency information for pandas from https://files.pythonhosted.org/packages/16/c6/75231fd47afd6b3f89011e7077f1a3958441264aca7ae9ff596e3276a5d0/pandas-2.2.2-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading pandas-2.2.2-cp311-cp311-macosx_11_0_arm64.whl.metadata (19 kB)\n",
      "Collecting pillow>=9.0.0 (from llama-index-core==0.10.43->llama-index)\n",
      "  Obtaining dependency information for pillow>=9.0.0 from https://files.pythonhosted.org/packages/00/5c/7633f291def20082bad31b844fe5ed07742aae8504e4cfe2f331ee727178/pillow-10.3.0-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading pillow-10.3.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (9.2 kB)\n",
      "Collecting requests>=2.31.0 (from llama-index-core==0.10.43->llama-index)\n",
      "  Obtaining dependency information for requests>=2.31.0 from https://files.pythonhosted.org/packages/f9/9b/335f9764261e915ed497fcdeb11df5dfd6f7bf257d4a6a2a686d80da4d54/requests-2.32.3-py3-none-any.whl.metadata\n",
      "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting tenacity<9.0.0,>=8.2.0 (from llama-index-core==0.10.43->llama-index)\n",
      "  Obtaining dependency information for tenacity<9.0.0,>=8.2.0 from https://files.pythonhosted.org/packages/61/a1/6bb0cbebefb23641f068bb58a2bc56da9beb2b1c550242e3c540b37698f3/tenacity-8.3.0-py3-none-any.whl.metadata\n",
      "  Downloading tenacity-8.3.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting tiktoken>=0.3.3 (from llama-index-core==0.10.43->llama-index)\n",
      "  Obtaining dependency information for tiktoken>=0.3.3 from https://files.pythonhosted.org/packages/30/ef/e07dbfcb2f85c84abaa1b035a9279575a8da0236305491dc22ae099327f7/tiktoken-0.7.0-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading tiktoken-0.7.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
      "Collecting tqdm<5.0.0,>=4.66.1 (from llama-index-core==0.10.43->llama-index)\n",
      "  Obtaining dependency information for tqdm<5.0.0,>=4.66.1 from https://files.pythonhosted.org/packages/18/eb/fdb7eb9e48b7b02554e1664afd3bd3f117f6b6d6c5881438a0b055554f9b/tqdm-4.66.4-py3-none-any.whl.metadata\n",
      "  Downloading tqdm-4.66.4-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting typing-extensions>=4.5.0 (from llama-index-core==0.10.43->llama-index)\n",
      "  Obtaining dependency information for typing-extensions>=4.5.0 from https://files.pythonhosted.org/packages/b6/53/84a859aaddfe7378a6e5820e864a2d75763e82b6fcbda1a00e92ec620bb7/typing_extensions-4.12.1-py3-none-any.whl.metadata\n",
      "  Downloading typing_extensions-4.12.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting typing-inspect>=0.8.0 (from llama-index-core==0.10.43->llama-index)\n",
      "  Obtaining dependency information for typing-inspect>=0.8.0 from https://files.pythonhosted.org/packages/65/f3/107a22063bf27bdccf2024833d3445f4eea42b2e598abfbd46f6a63b6cb0/typing_inspect-0.9.0-py3-none-any.whl.metadata\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting wrapt (from llama-index-core==0.10.43->llama-index)\n",
      "  Obtaining dependency information for wrapt from https://files.pythonhosted.org/packages/0f/16/ea627d7817394db04518f62934a5de59874b587b792300991b3c347ff5e0/wrapt-1.16.0-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading wrapt-1.16.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
      "Collecting beautifulsoup4<5.0.0,>=4.12.3 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index)\n",
      "  Obtaining dependency information for beautifulsoup4<5.0.0,>=4.12.3 from https://files.pythonhosted.org/packages/b1/fe/e8c672695b37eecc5cbf43e1d0638d88d66ba3a44c4d321c796f4e59167f/beautifulsoup4-4.12.3-py3-none-any.whl.metadata\n",
      "  Downloading beautifulsoup4-4.12.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting pypdf<5.0.0,>=4.0.1 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index)\n",
      "  Obtaining dependency information for pypdf<5.0.0,>=4.0.1 from https://files.pythonhosted.org/packages/c9/d1/450b19bbdbb2c802f554312c62ce2a2c0d8744fe14735bc70ad2803578c7/pypdf-4.2.0-py3-none-any.whl.metadata\n",
      "  Downloading pypdf-4.2.0-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index)\n",
      "  Obtaining dependency information for striprtf<0.0.27,>=0.0.26 from https://files.pythonhosted.org/packages/a3/cf/0fea4f4ba3fc2772ac2419278aa9f6964124d4302117d61bc055758e000c/striprtf-0.0.26-py3-none-any.whl.metadata\n",
      "  Downloading striprtf-0.0.26-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting llama-parse<0.5.0,>=0.4.0 (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index)\n",
      "  Obtaining dependency information for llama-parse<0.5.0,>=0.4.0 from https://files.pythonhosted.org/packages/65/a5/70818c66bdff6a05e3ba41ea978de85d711ee39272792299f413be416907/llama_parse-0.4.4-py3-none-any.whl.metadata\n",
      "  Downloading llama_parse-0.4.4-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.43->llama-index)\n",
      "  Obtaining dependency information for aiosignal>=1.1.2 from https://files.pythonhosted.org/packages/76/ac/a7305707cb852b7e16ff80eaf5692309bde30e2b1100a1fcacdc8f731d97/aiosignal-1.3.1-py3-none-any.whl.metadata\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.43->llama-index)\n",
      "  Obtaining dependency information for attrs>=17.3.0 from https://files.pythonhosted.org/packages/e0/44/827b2a91a5816512fcaf3cc4ebc465ccd5d598c45cefa6703fcf4a79018f/attrs-23.2.0-py3-none-any.whl.metadata\n",
      "  Downloading attrs-23.2.0-py3-none-any.whl.metadata (9.5 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.43->llama-index)\n",
      "  Obtaining dependency information for frozenlist>=1.1.1 from https://files.pythonhosted.org/packages/5b/9c/f12b69997d3891ddc0d7895999a00b0c6a67f66f79498c0e30f27876435d/frozenlist-1.4.1-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading frozenlist-1.4.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (12 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.43->llama-index)\n",
      "  Obtaining dependency information for multidict<7.0,>=4.5 from https://files.pythonhosted.org/packages/02/c1/b15ecceb6ffa5081ed2ed450aea58d65b0e0358001f2b426705f9f41f4c2/multidict-6.0.5-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading multidict-6.0.5-cp311-cp311-macosx_11_0_arm64.whl.metadata (4.2 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.43->llama-index)\n",
      "  Obtaining dependency information for yarl<2.0,>=1.0 from https://files.pythonhosted.org/packages/20/3d/7dabf580dfc0b588e48830486b488858122b10a61f33325e0d7cf1d6180b/yarl-1.9.4-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading yarl-1.9.4-cp311-cp311-macosx_11_0_arm64.whl.metadata (31 kB)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.2.0,>=0.1.4->llama-index)\n",
      "  Obtaining dependency information for soupsieve>1.2 from https://files.pythonhosted.org/packages/4c/f3/038b302fdfbe3be7da016777069f26ceefe11a681055ea1f7817546508e3/soupsieve-2.5-py3-none-any.whl.metadata\n",
      "  Downloading soupsieve-2.5-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting pydantic>=1.10 (from llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core==0.10.43->llama-index)\n",
      "  Obtaining dependency information for pydantic>=1.10 from https://files.pythonhosted.org/packages/e6/f5/80931903275942770f1112b524f1948f6d6ebd44725425025ca838800de2/pydantic-2.7.3-py3-none-any.whl.metadata\n",
      "  Downloading pydantic-2.7.3-py3-none-any.whl.metadata (108 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.0/109.0 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting anyio (from httpx->llama-index-core==0.10.43->llama-index)\n",
      "  Obtaining dependency information for anyio from https://files.pythonhosted.org/packages/7b/a2/10639a79341f6c019dedc95bd48a4928eed9f1d1197f4c04f546fc7ae0ff/anyio-4.4.0-py3-none-any.whl.metadata\n",
      "  Downloading anyio-4.4.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting certifi (from httpx->llama-index-core==0.10.43->llama-index)\n",
      "  Obtaining dependency information for certifi from https://files.pythonhosted.org/packages/5b/11/1e78951465b4a225519b8c3ad29769c49e0d8d157a070f681d5b6d64737f/certifi-2024.6.2-py3-none-any.whl.metadata\n",
      "  Downloading certifi-2024.6.2-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting httpcore==1.* (from httpx->llama-index-core==0.10.43->llama-index)\n",
      "  Obtaining dependency information for httpcore==1.* from https://files.pythonhosted.org/packages/78/d4/e5d7e4f2174f8a4d63c8897d79eb8fe2503f7ecc03282fee1fa2719c2704/httpcore-1.0.5-py3-none-any.whl.metadata\n",
      "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting idna (from httpx->llama-index-core==0.10.43->llama-index)\n",
      "  Obtaining dependency information for idna from https://files.pythonhosted.org/packages/e5/3e/741d8c82801c347547f8a2a06aa57dbb1992be9e948df2ea0eda2c8b79e8/idna-3.7-py3-none-any.whl.metadata\n",
      "  Downloading idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting sniffio (from httpx->llama-index-core==0.10.43->llama-index)\n",
      "  Obtaining dependency information for sniffio from https://files.pythonhosted.org/packages/e9/44/75a9c9421471a6c4805dbf2356f7c181a29c1879239abab1ea2cc8f38b40/sniffio-1.3.1-py3-none-any.whl.metadata\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx->llama-index-core==0.10.43->llama-index)\n",
      "  Obtaining dependency information for h11<0.15,>=0.13 from https://files.pythonhosted.org/packages/95/04/ff642e65ad6b90db43e668d70ffb6736436c7ce41fcc549f4e9472234127/h11-0.14.0-py3-none-any.whl.metadata\n",
      "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting click (from nltk<4.0.0,>=3.8.1->llama-index-core==0.10.43->llama-index)\n",
      "  Obtaining dependency information for click from https://files.pythonhosted.org/packages/00/2e/d53fa4befbf2cfa713304affc7ca780ce4fc1fd8710527771b58311a3229/click-8.1.7-py3-none-any.whl.metadata\n",
      "  Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting joblib (from nltk<4.0.0,>=3.8.1->llama-index-core==0.10.43->llama-index)\n",
      "  Obtaining dependency information for joblib from https://files.pythonhosted.org/packages/91/29/df4b9b42f2be0b623cbd5e2140cafcaa2bef0759a00b7b70104dcfe2fb51/joblib-1.4.2-py3-none-any.whl.metadata\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting regex>=2021.8.3 (from nltk<4.0.0,>=3.8.1->llama-index-core==0.10.43->llama-index)\n",
      "  Obtaining dependency information for regex>=2021.8.3 from https://files.pythonhosted.org/packages/c3/43/29ef9c42ae1e764a98510af1c610bf9f4b90a97a04fabe9396d6b73b0cc4/regex-2024.5.15-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading regex-2024.5.15-cp311-cp311-macosx_11_0_arm64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting distro<2,>=1.7.0 (from openai>=1.1.0->llama-index-core==0.10.43->llama-index)\n",
      "  Obtaining dependency information for distro<2,>=1.7.0 from https://files.pythonhosted.org/packages/12/b3/231ffd4ab1fc9d679809f356cebee130ac7daa00d6d6f3206dd4fd137e9e/distro-1.9.0-py3-none-any.whl.metadata\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests>=2.31.0->llama-index-core==0.10.43->llama-index)\n",
      "  Obtaining dependency information for charset-normalizer<4,>=2 from https://files.pythonhosted.org/packages/dd/51/68b61b90b24ca35495956b718f35a9756ef7d3dd4b3c1508056fa98d1a1b/charset_normalizer-3.3.2-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading charset_normalizer-3.3.2-cp311-cp311-macosx_11_0_arm64.whl.metadata (33 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests>=2.31.0->llama-index-core==0.10.43->llama-index)\n",
      "  Obtaining dependency information for urllib3<3,>=1.21.1 from https://files.pythonhosted.org/packages/a2/73/a68704750a7679d0b6d3ad7aa8d4da8e14e151ae82e6fee774e6e0d05ec8/urllib3-2.2.1-py3-none-any.whl.metadata\n",
      "  Downloading urllib3-2.2.1-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting greenlet!=0.4.17 (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core==0.10.43->llama-index)\n",
      "  Obtaining dependency information for greenlet!=0.4.17 from https://files.pythonhosted.org/packages/6e/20/68a278a6f93fa36e21cfc3d7599399a8a831225644eb3b6b18755cd3d6fc/greenlet-3.0.3-cp311-cp311-macosx_11_0_universal2.whl.metadata\n",
      "  Downloading greenlet-3.0.3-cp311-cp311-macosx_11_0_universal2.whl.metadata (3.8 kB)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index-core==0.10.43->llama-index)\n",
      "  Obtaining dependency information for mypy-extensions>=0.3.0 from https://files.pythonhosted.org/packages/2a/e2/5d3f6ada4297caebe1a2add3b126fe800c96f56dbe5d1988a2cbe0b267aa/mypy_extensions-1.0.0-py3-none-any.whl.metadata\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama-index-core==0.10.43->llama-index)\n",
      "  Obtaining dependency information for marshmallow<4.0.0,>=3.18.0 from https://files.pythonhosted.org/packages/96/d7/f318261e6ccbba86bdf626e07cd850981508fdaec52cfcdc4ac1030327ab/marshmallow-3.21.3-py3-none-any.whl.metadata\n",
      "  Downloading marshmallow-3.21.3-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting python-dateutil>=2.8.2 (from pandas->llama-index-core==0.10.43->llama-index)\n",
      "  Obtaining dependency information for python-dateutil>=2.8.2 from https://files.pythonhosted.org/packages/ec/57/56b9bcc3c9c6a792fcbaf139543cee77261f3651ca9da0c93f5c1221264b/python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata\n",
      "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting pytz>=2020.1 (from pandas->llama-index-core==0.10.43->llama-index)\n",
      "  Obtaining dependency information for pytz>=2020.1 from https://files.pythonhosted.org/packages/9c/3d/a121f284241f08268b21359bd425f7d4825cffc5ac5cd0e1b3d82ffd2b10/pytz-2024.1-py2.py3-none-any.whl.metadata\n",
      "  Downloading pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas->llama-index-core==0.10.43->llama-index)\n",
      "  Obtaining dependency information for tzdata>=2022.7 from https://files.pythonhosted.org/packages/65/58/f9c9e6be752e9fcb8b6a0ee9fb87e6e7a1f6bcab2cdc73f02bb7ba91ada0/tzdata-2024.1-py2.py3-none-any.whl.metadata\n",
      "  Downloading tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting packaging>=17.0 (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core==0.10.43->llama-index)\n",
      "  Obtaining dependency information for packaging>=17.0 from https://files.pythonhosted.org/packages/49/df/1fceb2f8900f8639e278b056416d49134fb8d84c5942ffaa01ad34782422/packaging-24.0-py3-none-any.whl.metadata\n",
      "  Downloading packaging-24.0-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting annotated-types>=0.4.0 (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core==0.10.43->llama-index)\n",
      "  Obtaining dependency information for annotated-types>=0.4.0 from https://files.pythonhosted.org/packages/78/b6/6307fbef88d9b5ee7421e68d78a9f162e0da4900bc5f5793f6d3d0e34fb8/annotated_types-0.7.0-py3-none-any.whl.metadata\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.18.4 (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core==0.10.43->llama-index)\n",
      "  Obtaining dependency information for pydantic-core==2.18.4 from https://files.pythonhosted.org/packages/6c/a2/229dbee765ce711cd42c056da497ca26f7267384362e6767ab3bcdafca79/pydantic_core-2.18.4-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading pydantic_core-2.18.4-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.5 kB)\n",
      "Collecting six>=1.5 (from python-dateutil>=2.8.2->pandas->llama-index-core==0.10.43->llama-index)\n",
      "  Obtaining dependency information for six>=1.5 from https://files.pythonhosted.org/packages/d9/5a/e7c31adbe875f2abbb91bd84cf2dc52d792b5a01506781dbcf25c91daf11/six-1.16.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading six-1.16.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Downloading llama_index-0.10.43-py3-none-any.whl (6.8 kB)\n",
      "Downloading llama_index_core-0.10.43-py3-none-any.whl (15.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.4/15.4 MB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading llama_index_agent_openai-0.2.7-py3-none-any.whl (12 kB)\n",
      "Downloading llama_index_cli-0.1.12-py3-none-any.whl (26 kB)\n",
      "Downloading llama_index_embeddings_openai-0.1.10-py3-none-any.whl (6.2 kB)\n",
      "Downloading llama_index_indices_managed_llama_cloud-0.1.6-py3-none-any.whl (6.7 kB)\n",
      "Downloading llama_index_legacy-0.9.48-py3-none-any.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m48.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading llama_index_llms_openai-0.1.22-py3-none-any.whl (11 kB)\n",
      "Downloading llama_index_multi_modal_llms_openai-0.1.6-py3-none-any.whl (5.8 kB)\n",
      "Downloading llama_index_program_openai-0.1.6-py3-none-any.whl (5.2 kB)\n",
      "Downloading llama_index_question_gen_openai-0.1.3-py3-none-any.whl (2.9 kB)\n",
      "Downloading llama_index_readers_file-0.1.23-py3-none-any.whl (36 kB)\n",
      "Downloading llama_index_readers_llama_parse-0.1.4-py3-none-any.whl (2.5 kB)\n",
      "Downloading aiohttp-3.9.5-cp311-cp311-macosx_11_0_arm64.whl (390 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m390.2/390.2 kB\u001b[0m \u001b[31m39.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading beautifulsoup4-4.12.3-py3-none-any.whl (147 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.9/147.9 kB\u001b[0m \u001b[31m155.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
      "Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
      "Downloading fsspec-2024.6.0-py3-none-any.whl (176 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.9/176.9 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading llama_parse-0.4.4-py3-none-any.whl (8.0 kB)\n",
      "Downloading llamaindex_py_client-0.1.19-py3-none-any.whl (141 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m57.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m158.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nest_asyncio-1.6.0-py3-none-any.whl (5.2 kB)\n",
      "Downloading networkx-3.3-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading openai-1.32.0-py3-none-any.whl (325 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.2/325.2 kB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pillow-10.3.0-cp311-cp311-macosx_11_0_arm64.whl (3.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pypdf-4.2.0-py3-none-any.whl (290 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.4/290.4 kB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading PyYAML-6.0.1-cp311-cp311-macosx_11_0_arm64.whl (167 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.5/167.5 kB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m75.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
      "Downloading tenacity-8.3.0-py3-none-any.whl (25 kB)\n",
      "Downloading tiktoken-0.7.0-cp311-cp311-macosx_11_0_arm64.whl (907 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m907.0/907.0 kB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.66.4-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typing_extensions-4.12.1-py3-none-any.whl (37 kB)\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading wrapt-1.16.0-cp311-cp311-macosx_11_0_arm64.whl (38 kB)\n",
      "Downloading dataclasses_json-0.6.6-py3-none-any.whl (28 kB)\n",
      "Downloading numpy-1.26.4-cp311-cp311-macosx_11_0_arm64.whl (14.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.0/14.0 MB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pandas-2.2.2-cp311-cp311-macosx_11_0_arm64.whl (11.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Downloading anyio-4.4.0-py3-none-any.whl (86 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading attrs-23.2.0-py3-none-any.whl (60 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m79.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading certifi-2024.6.2-py3-none-any.whl (164 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.4/164.4 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading charset_normalizer-3.3.2-cp311-cp311-macosx_11_0_arm64.whl (118 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.0/119.0 kB\u001b[0m \u001b[31m47.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading frozenlist-1.4.1-cp311-cp311-macosx_11_0_arm64.whl (53 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.4/53.4 kB\u001b[0m \u001b[31m143.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading greenlet-3.0.3-cp311-cp311-macosx_11_0_universal2.whl (271 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m271.7/271.7 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading idna-3.7-py3-none-any.whl (66 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading marshmallow-3.21.3-py3-none-any.whl (49 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multidict-6.0.5-cp311-cp311-macosx_11_0_arm64.whl (30 kB)\n",
      "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Downloading pydantic-2.7.3-py3-none-any.whl (409 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m409.6/409.6 kB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_core-2.18.4-cp311-cp311-macosx_11_0_arm64.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.9/229.9 kB\u001b[0m \u001b[31m141.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m505.5/505.5 kB\u001b[0m \u001b[31m50.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading regex-2024.5.15-cp311-cp311-macosx_11_0_arm64.whl (278 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.3/278.3 kB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Downloading soupsieve-2.5-py3-none-any.whl (36 kB)\n",
      "Downloading tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.4/345.4 kB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading urllib3-2.2.1-py3-none-any.whl (121 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.1/121.1 kB\u001b[0m \u001b[31m37.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading yarl-1.9.4-cp311-cp311-macosx_11_0_arm64.whl (81 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.2/81.2 kB\u001b[0m \u001b[31m181.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.9/97.9 kB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.8/301.8 kB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading SQLAlchemy-2.0.30-cp311-cp311-macosx_11_0_arm64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading packaging-24.0-py3-none-any.whl (53 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.5/53.5 kB\u001b[0m \u001b[31m232.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n"
     ]
    }
   ],
   "source": [
    "!pip3 uninstall llama-index\n",
    "!pip3 install llama-index --upgrade --no-cache-dir --force-reinstall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n!pip install pydantic==2.7.0\\n!pip install pydantic_core==2.18.1\\n!pip install llama_index_readers_file==0.1.19\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# installation if version issues\n",
    "\"\"\"\n",
    "!pip install pydantic==2.7.0\n",
    "!pip install pydantic_core==2.18.1\n",
    "!pip install llama_index_readers_file==0.1.19\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- import nest_asyncio: Required for async compatibility in Jupyter notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import nest_asyncio\n",
    "import os\n",
    "nest_asyncio.apply()\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access variables\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loading data**\n",
    "- Load Sample Document: Use GPT2 paper.\n",
    "- Read PDF with LlamaIndex: Use a directory reader module.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wenda/anaconda3/lib/python3.11/site-packages/scipy/__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.26.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/Users/wenda/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "# load documents\n",
    "documents = SimpleDirectoryReader(input_files=[\"language_models_are_unsupervised_multitask_learners.pdf\"]).load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define LLM and Embedding model**\n",
    "- Sentence Splitter: Use LlamaIndex to split the document into nodes (*parse document representation*).\n",
    "  - In order to split these documents into even-sized chunks, we'll split on the order of sentences.\n",
    "- Split Document: Set chunk size to 1024, and call `splitter.get_nodes_from_documents` to split these documents into nodes.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "\n",
    "splitter = SentenceSplitter(chunk_size=1024)\n",
    "nodes = splitter.get_nodes_from_documents(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Optional Step**\n",
    "- Alignment and Embedding Model: Set global config (default: 3.5 turbo, tex-embedding 002).\n",
    "- This allows you to have the groundwork to inject your own LLMs as well as embeddings. \n",
    "- We define the settings object and `settings.llm=OpenAI` and `settings.embed_model=OpenAI.Embedding`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Settings\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "\n",
    "Settings.llm = OpenAI(model=\"gpt-3.5-turbo\")\n",
    "Settings.embed_model = OpenAIEmbedding(model=\"text-embedding-ada-002\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define Summary Index and Vector Index over the Same Data**\n",
    "- We can think of an index as a set of metadata over our data.\n",
    "- You can query an index, and different indexes will have different retrieval behaviors.\n",
    "- Summary Index: Returns all nodes in the index.\n",
    "- Vector Index: \n",
    "  - Indexes nodes via text embeddings and is a core abstraction in LlamaIndex and a core abstraction for building any sort of RAG system.\n",
    "  - Returns nodes by embedding similarity.\n",
    "- Query Engines: \n",
    "  - Also a very simple index, convert indexes into query engines.\n",
    "  - querying it will return all the nodes currently in the index, so it doesn't necessarily depend on the user query but will return all the nodes currently in the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SummaryIndex, VectorStoreIndex\n",
    "\n",
    "summary_index = SummaryIndex(nodes)\n",
    "vector_index = VectorStoreIndex(nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define Query Engines and Set Metadata**\n",
    "- Now let's turn these indexes into query engines and then query tools.\n",
    "- Each query engine represents an overall query interface over the data stored in this index and combines retrieval with LLM synthesis.\n",
    "- Each query engine is good for a certain type of question, and this is a great use case for a router, which can route dynamically between these different query engines.\n",
    "- A query tool now is just the query engine with **metadata**, specifically a description of what types of questions the tool can answer.\n",
    "- Summary Query Engine: Faster query generation using async.\n",
    "- Vector Query Engine: For retrieving specific context from the document.\n",
    "- For the summary query engine, we set use_async to true to enforce faster query generation by leveraging async capabilities.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_query_engine = summary_index.as_query_engine(\n",
    "    response_mode=\"tree_summarize\",\n",
    "    use_async=True,\n",
    ")\n",
    "vector_query_engine = vector_index.as_query_engine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A query tool is just the query engine with metadata, specifically a description of what types of questions the tool can answer. \n",
    "- We'll define a query tool for both the summary and vector query engines. \n",
    "- summary tool description is useful for summarization questions related to document and \n",
    "- vector tool description is useful for retrieving specific context from the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.tools import QueryEngineTool\n",
    "\n",
    "summary_tool = QueryEngineTool.from_defaults(\n",
    "    query_engine=summary_query_engine,\n",
    "    description=(\n",
    "        \"Useful for summarization questions related to GPT2 paper\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "vector_tool = QueryEngineTool.from_defaults(\n",
    "    query_engine=vector_query_engine,\n",
    "    description=(\n",
    "        \"Useful for retrieving specific context from the GPT2 paper.\"\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define Router Query Engine**\n",
    "- Now that we have our query engines and tools, we're ready to define our router. \n",
    "- LlamaIndex provides several different types of selectors to enable you to build a router. Each of these selectors has distinct attributes. \n",
    "  - Option1: LLM selector,  it involves prompting an LLM to output a JSON that is then parsed, and the corresponding indexes are queried. \n",
    "  - Option2: Pydantic selectors, here instead of directly prompting the LLM with text, we use the function calling APIs supported by models like OpenAI to produce pydantic selection objects, rather than parsing raw JSON.\n",
    "- For each of these types of selectors, we also have the dynamic capabilities to let you select one index to route to, or multiple."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try an LLM-powered single selector called LLM single selector. We import two modules: \n",
    "- Router query engine\n",
    "  - The router query engine takes in a selector type as well as a set of query engine tools.\n",
    "- LLM single selector\n",
    "  - The selector type is the LLM single selector, which means it prompts the LLM, makes a single selection, and the query engine tools include the summarization tool and the vector tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.query_engine.router_query_engine import RouterQueryEngine\n",
    "from llama_index.core.selectors import LLMSingleSelector\n",
    "\n",
    "\n",
    "query_engine = RouterQueryEngine(\n",
    "    selector=LLMSingleSelector.from_defaults(),\n",
    "    query_engine_tools=[\n",
    "        summary_tool,\n",
    "        vector_tool,\n",
    "    ],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;5;200mSelecting query engine 0: Useful for summarization questions related to GPT2 paper.\n",
      "\u001b[0mThe document covers the training and performance analysis of large language models, specifically focusing on the GPT-2 model trained on diverse datasets. It discusses the model's zero-shot capabilities across various NLP tasks, its potential for multitask learning, and the analysis of data overlap between training and test sets. Additionally, it explores the model's performance, fine-tuning potential, and the need for further research in understanding language models' capabilities.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"What is the summary of the document?\")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TLDR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from utils import get_router_query_engine\n",
    "query_engine = get_router_query_engine(\"language_models_are_unsupervised_multitask_learners.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;5;200mSelecting query engine 1: Ablation study results are specific context from the MetaGPT paper, making choice 2 the most relevant..\n",
      "\u001b[0mThe ablation study results were not explicitly mentioned in the provided context information.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"Tell me about the ablation study results?\")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
