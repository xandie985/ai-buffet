{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Building an Agent Reasoning Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, our queries have been done in a single forward pass. \n",
    "- Given the query, we call the right tool with the right parameters and get back the response. \n",
    "- But this is still quite limiting. \n",
    "- What if the user asks a complex question consisting of multiple steps or a vague question that needs clarification? \n",
    "  - Let's define a complete agent reasoning loop. \n",
    "  - Instead of calling a tool in a single shot setting, an agent can reason over tools and multiple steps.\n",
    "\n",
    "You will use the function calling agent implementation, which natively integrates with the function calling capabilities of LLMs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compress all the work we did before and use `utils.py` to call relevant functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import nest_asyncio\n",
    "import os\n",
    "nest_asyncio.apply()\n",
    "load_dotenv()\n",
    "\n",
    "# Access variables\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils3 import get_doc_tools\n",
    "\n",
    "vector_tool, summary_tool = get_doc_tools(\"metaGPT.pdf\", \"metagpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agent in LlamaIndex consists of two main components: \n",
    "- an agent worker, responsible for executing the next step of a given agent, and \n",
    "- an agent runner, responsible for creating a task and orchestrating runs of agent workers on top of a given task, returning the final response to the user. \n",
    "  \n",
    "We import both function calling agent worker and agent runner from LlamaIndex, passing in tools like the vector tool and the summary tool, and set verbose to true to view intermediate outputs.\n",
    "\n",
    "The function calling agent worker's primary responsibility is to use function calling to decide the next step based on the existing conversation history, memory, and current user input. \n",
    "\n",
    "It decides whether to call a tool and return a final response. The overall agent interface is behind the agent runner, which we use to query the agent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.agent import FunctionCallingAgentWorker\n",
    "from llama_index.core.agent import AgentRunner\n",
    "\n",
    "agent_worker = FunctionCallingAgentWorker.from_tools(\n",
    "    [vector_tool, summary_tool], \n",
    "    llm=llm, \n",
    "    verbose=True\n",
    ")\n",
    "agent = AgentRunner(agent_worker)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The agent breaks down this question into steps, \n",
    "- calling the summary tool to answer about agent roles in Meta GPT. It returns information on roles such as product manager, architect, project manager, QA, engineer, etc.,\n",
    "- then addresses communication between these roles, showing structured and efficient interaction. \n",
    "\n",
    "The conversation history helps generate a final response, using tools like the vector tool for concise context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: Tell me about the agent roles in MetaGPT, and then how they communicate with each other.\n",
      "=== Calling Function ===\n",
      "Calling function: summary_tool_metagpt with args: {\"input\": \"agent roles in MetaGPT\"}\n",
      "=== Function Output ===\n",
      "The agent roles in MetaGPT are the Product Manager, Architect, Project Manager, Engineer, and QA Engineer. Each role has specific responsibilities in the software development process, such as generating Product Requirement Documents, designing system architecture, task allocation, code implementation, and quality assurance through unit testing. These roles work collaboratively to ensure the successful completion of software projects within the MetaGPT framework.\n",
      "=== Calling Function ===\n",
      "Calling function: summary_tool_metagpt with args: {\"input\": \"how agents communicate with each other in MetaGPT\"}\n",
      "=== Function Output ===\n",
      "Agents in MetaGPT communicate with each other through structured communication interfaces and a shared message pool. Each agent publishes structured messages in the shared pool and can subscribe to relevant messages based on their role profiles. This structured communication approach allows for efficient information exchange among agents, preventing information overload and enhancing communication efficiency within the multi-agent system.\n",
      "=== LLM Response ===\n",
      "In MetaGPT, the agent roles include the Product Manager, Architect, Project Manager, Engineer, and QA Engineer. These roles have specific responsibilities in software development, such as generating requirements, designing architecture, task allocation, code implementation, and quality assurance.\n",
      "\n",
      "Agents in MetaGPT communicate with each other through structured communication interfaces and a shared message pool. They publish structured messages in the pool and subscribe to relevant messages based on their role profiles. This approach enables efficient information exchange and enhances communication efficiency within the multi-agent system.\n"
     ]
    }
   ],
   "source": [
    "response = agent.query(\n",
    "    \"Tell me about the agent roles in MetaGPT, \"\n",
    "    \"and then how they communicate with each other.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running a multi-step query requires tracing sources. \n",
    "- We inspect response notes to trace back the content, maintaining conversation history over time with a memory module that uses a rolling buffer depending on the LLM's context window size. \n",
    "- When the agent uses a tool, it considers the current chat and previous conversation history to take the next action. \n",
    "- We switch from querying to using agent.chat, asking about the evaluation datasets used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_label: 1\n",
      "file_name: metaGPT.pdf\n",
      "file_path: metaGPT.pdf\n",
      "file_type: application/pdf\n",
      "file_size: 16715764\n",
      "creation_date: 2024-06-08\n",
      "last_modified_date: 2024-06-08\n",
      "\n",
      "Preprint\n",
      "METAGPT: M ETA PROGRAMMING FOR A\n",
      "MULTI -AGENT COLLABORATIVE FRAMEWORK\n",
      "Sirui Hong1∗, Mingchen Zhuge2∗, Jonathan Chen1, Xiawu Zheng3, Yuheng Cheng4,\n",
      "Ceyao Zhang4,Jinlin Wang1,Zili Wang ,Steven Ka Shing Yau5,Zijuan Lin4,\n",
      "Liyang Zhou6,Chenyu Ran1,Lingfeng Xiao1,7,Chenglin Wu1†,J¨urgen Schmidhuber2,8\n",
      "1DeepWisdom,2AI Initiative, King Abdullah University of Science and Technology,\n",
      "3Xiamen University,4The Chinese University of Hong Kong, Shenzhen,\n",
      "5Nanjing University,6University of Pennsylvania,\n",
      "7University of California, Berkeley,8The Swiss AI Lab IDSIA/USI/SUPSI\n",
      "ABSTRACT\n",
      "Remarkable progress has been made on automated problem solving through so-\n",
      "cieties of agents based on large language models (LLMs). Existing LLM-based\n",
      "multi-agent systems can already solve simple dialogue tasks. Solutions to more\n",
      "complex tasks, however, are complicated through logic inconsistencies due to\n",
      "cascading hallucinations caused by naively chaining LLMs. Here we introduce\n",
      "MetaGPT, an innovative meta-programming framework incorporating efficient\n",
      "human workflows into LLM-based multi-agent collaborations. MetaGPT en-\n",
      "codes Standardized Operating Procedures (SOPs) into prompt sequences for more\n",
      "streamlined workflows, thus allowing agents with human-like domain expertise\n",
      "to verify intermediate results and reduce errors. MetaGPT utilizes an assembly\n",
      "line paradigm to assign diverse roles to various agents, efficiently breaking down\n",
      "complex tasks into subtasks involving many agents working together. On col-\n",
      "laborative software engineering benchmarks, MetaGPT generates more coherent\n",
      "solutions than previous chat-based multi-agent systems. Our project can be found\n",
      "at https://github.com/geekan/MetaGPT\n",
      "1 I NTRODUCTION\n",
      "Autonomous agents utilizing Large Language Models (LLMs) offer promising opportunities to en-\n",
      "hance and replicate human workflows. In real-world applications, however, existing systems (Park\n",
      "et al., 2023; Zhuge et al., 2023; Cai et al., 2023; Wang et al., 2023c; Li et al., 2023; Du et al., 2023;\n",
      "Liang et al., 2023; Hao et al., 2023) tend to oversimplify the complexities. They struggle to achieve\n",
      "effective, coherent, and accurate problem-solving processes, particularly when there is a need for\n",
      "meaningful collaborative interaction (Zhang et al., 2023; Dong et al., 2023; Zhou et al., 2023; Qian\n",
      "et al., 2023).\n",
      "Through extensive collaborative practice, humans have developed widely accepted Standardized\n",
      "Operating Procedures (SOPs) across various domains (Belbin, 2012; Manifesto, 2001; DeMarco &\n",
      "Lister, 2013). These SOPs play a critical role in supporting task decomposition and effective coor-\n",
      "dination. Furthermore, SOPs outline the responsibilities of each team member, while establishing\n",
      "standards for intermediate outputs. Well-defined SOPs improve the consistent and accurate exe-\n",
      "cution of tasks that align with defined roles and quality standards (Belbin, 2012; Manifesto, 2001;\n",
      "DeMarco & Lister, 2013; Wooldridge & Jennings, 1998). For instance, in a software company,\n",
      "Product Managers analyze competition and user needs to create Product Requirements Documents\n",
      "(PRDs) using a standardized structure, to guide the developmental process.\n",
      "Inspired by such ideas, we design a promising GPT -based Meta -Programming framework called\n",
      "MetaGPT that significantly benefits from SOPs. Unlike other works (Li et al., 2023; Qian et al.,\n",
      "2023), MetaGPT requires agents to generate structured outputs, such as high-quality requirements\n",
      "∗These authors contributed equally to this work.\n",
      "†Chenglin Wu (alexanderwu@fuzhi.ai) is the corresponding author, affiliated with DeepWisdom.\n",
      "1arXiv:2308.00352v5  [cs.AI]  6 Nov 2023\n"
     ]
    }
   ],
   "source": [
    "print(response.source_nodes[0].get_content(metadata_mode=\"all\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: Tell me about the evaluation datasets used.\n",
      "=== Calling Function ===\n",
      "Calling function: summary_tool_metagpt with args: {\"input\": \"evaluation datasets used in MetaGPT\"}\n",
      "=== Function Output ===\n",
      "The evaluation datasets used in MetaGPT include HumanEval, MBPP, and a self-generated SoftwareDev dataset. The HumanEval dataset consists of 164 handwritten programming tasks, while the MBPP dataset consists of 427 Python tasks. The SoftwareDev dataset is a collection of 70 representative examples of software development tasks covering diverse scopes such as mini-games, image processing algorithms, and data visualization. These datasets were used to evaluate the performance of MetaGPT in code generation tasks.\n",
      "=== LLM Response ===\n",
      "The evaluation datasets used in MetaGPT include HumanEval, MBPP, and a self-generated SoftwareDev dataset. HumanEval consists of 164 handwritten programming tasks, MBPP includes 427 Python tasks, and the SoftwareDev dataset comprises 70 representative software development tasks covering various scopes like mini-games, image processing algorithms, and data visualization. These datasets were utilized to assess MetaGPT's performance in code generation tasks.\n"
     ]
    }
   ],
   "source": [
    "response = agent.chat(\n",
    "    \"Tell me about the evaluation datasets used.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets see if the agent is able to recall this conversation history. So, we will ask another question now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: Tell me the results over one of the above datasets.\n",
      "=== Calling Function ===\n",
      "Calling function: vector_tool_metagpt with args: {\"query\": \"results over the HumanEval dataset\", \"page_numbers\": [\"6\"]}\n",
      "=== Function Output ===\n",
      "The results over the HumanEval dataset were part of the experimental evaluation conducted in the study.\n",
      "=== LLM Response ===\n",
      "The results over the HumanEval dataset were part of the experimental evaluation conducted in the study.\n"
     ]
    }
   ],
   "source": [
    "response = agent.chat(\"Tell me the results over one of the above datasets.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The agent uses the summary tool to identify datasets like human eval, MVP, and software dev. A follow-up query about results over one of these datasets demonstrates the agent's ability to maintain conversation history and provide detailed responses.\n",
    "\n",
    "So now, we successfully were able to provide a interface with interacting with the agent. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Lower-Level: Debuggability and Control\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets explore steps through more granular control can be achieved the agent. This helps in creating high level Research assistant over RAG pipelines, and also debug and control it. \n",
    "\n",
    "Key benefits:\n",
    "- debug ability in execution of each  step.\n",
    "  - As a dev, you have more transparency & visibility of what is happening under the hood. \n",
    "  - We can trace the agent's executions and check the failure reasons, test new inputs to obtain better results. \n",
    "  - Ultimately provides richer UX.\n",
    "- steeriability by allowing user to inject feedback. \n",
    "  - Suppose we want the agent to listen to human feedback while it is running, to achieve this we have to create a async queue, where human feedback can be delivered throught the agent' execution. \n",
    "  - So, while the agent is working, if it recieves any human feedback, it will address it and modify its response. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_worker = FunctionCallingAgentWorker.from_tools(\n",
    "    [vector_tool, summary_tool], \n",
    "    llm=llm, \n",
    "    verbose=True\n",
    ")\n",
    "agent = AgentRunner(agent_worker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = agent.create_task(\n",
    "    \"Tell me about the agent roles in MetaGPT, \"\n",
    "    \"and then how they communicate with each other.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: Tell me about the agent roles in MetaGPT, and then how they communicate with each other.\n",
      "=== Calling Function ===\n",
      "Calling function: summary_tool_metagpt with args: {\"input\": \"agent roles in MetaGPT\"}\n",
      "=== Function Output ===\n",
      "The agent roles in MetaGPT include the Product Manager, Architect, Project Manager, Engineer, and QA Engineer. The Product Manager is responsible for generating the Product Requirement Document (PRD) and competitive analysis. The Architect designs the system architecture and technical specifications. The Project Manager breaks down the project into tasks for execution. The Engineer implements the code based on the specifications. Lastly, the QA Engineer generates unit tests and ensures the quality of the software. Each role has specific responsibilities that contribute to the collaborative software development process within MetaGPT.\n"
     ]
    }
   ],
   "source": [
    "step_output = agent.run_step(task.task_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see only first task has been executed and then stops. Lets see how many steps have been executed, and what is the current output till now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num completed for task 92edf57d-bfe8-4f49-8478-f530b47fce56: 1\n",
      "The agent roles in MetaGPT include the Product Manager, Architect, Project Manager, Engineer, and QA Engineer. The Product Manager is responsible for generating the Product Requirement Document (PRD) and competitive analysis. The Architect designs the system architecture and technical specifications. The Project Manager breaks down the project into tasks for execution. The Engineer implements the code based on the specifications. Lastly, the QA Engineer generates unit tests and ensures the quality of the software. Each role has specific responsibilities that contribute to the collaborative software development process within MetaGPT.\n"
     ]
    }
   ],
   "source": [
    "completed_steps = agent.get_completed_steps(task.task_id)\n",
    "print(f\"Num completed for task {task.task_id}: {len(completed_steps)}\")\n",
    "print(completed_steps[0].output.sources[0].raw_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets take a loot at the upcoming steps too. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num upcoming steps for task 92edf57d-bfe8-4f49-8478-f530b47fce56: 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TaskStep(task_id='92edf57d-bfe8-4f49-8478-f530b47fce56', step_id='348d6ec7-2d92-4843-ba92-00a6981e9836', input=None, step_state={}, next_steps={}, prev_steps={}, is_ready=True)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upcoming_steps = agent.get_upcoming_steps(task.task_id)\n",
    "print(f\"Num upcoming steps for task {task.task_id}: {len(upcoming_steps)}\")\n",
    "upcoming_steps[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We see the current input to the next task is None, this is because it auto-generates the action based on the conversation history. \n",
    "\n",
    "- Another option we currently have is to take the intermediate results and stop this flow. \n",
    "\n",
    "Now, lets chenge the question to the agent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: What about how agents share information?\n",
      "=== Calling Function ===\n",
      "Calling function: summary_tool_metagpt with args: {\"input\": \"how agents share information in MetaGPT\"}\n",
      "=== Function Output ===\n",
      "Agents in MetaGPT share information through a shared message pool where they can publish structured messages and subscribe to relevant messages based on their profiles. This method allows agents to efficiently exchange information without the need for direct one-to-one communication, enhancing communication efficiency and reducing information overload.\n"
     ]
    }
   ],
   "source": [
    "step_output = agent.run_step(\n",
    "    task.task_id, input=\"What about how agents share information?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see the agent is able to handle the interruptions and address different questions if asked in middle. \n",
    "\n",
    "Now lets perform the final step to synthesize the answer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== LLM Response ===\n",
      "Agents in MetaGPT share information through a shared message pool where they can publish structured messages and subscribe to relevant messages based on their profiles. This method allows agents to efficiently exchange information without the need for direct one-to-one communication, enhancing communication efficiency and reducing information overload.\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "step_output = agent.run_step(task.task_id)\n",
    "print(step_output.is_last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agents in MetaGPT share information through a shared message pool where they can publish structured messages and subscribe to relevant messages based on their profiles. This method allows agents to efficiently exchange information without the need for direct one-to-one communication, enhancing communication efficiency and reducing information overload.\n"
     ]
    }
   ],
   "source": [
    "response = agent.finalize_response(task.task_id)\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
